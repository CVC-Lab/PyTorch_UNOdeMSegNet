{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(3, 112, 112, 3)\n",
      "(3, 112, 112, 3)\n",
      "0 255\n",
      "(3, 6, 112, 112)\n",
      "0.0 1.0\n",
      "mask.shape:(6, 112, 112)\n",
      "mask.shape:(6, 112, 112)\n",
      "mask.shape:(6, 112, 112)\n",
      "nrow: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(112, 112, count=3)\n",
    "\n",
    "print(input_images.shape)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask (Ground-truth)\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2000, 'val': 200}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = simulation.generate_random_data(112, 112, count=count)        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, mask]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = models.resnet50(pretrained=False)\n",
    "# model = pytorch_unet.UNet(6)\n",
    "model = base_model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "              ReLU-3           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-4           [-1, 64, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "              ReLU-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "           Conv2d-11          [-1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 28, 28]             512\n",
      "           Conv2d-13          [-1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 28, 28]             512\n",
      "             ReLU-15          [-1, 256, 28, 28]               0\n",
      "       Bottleneck-16          [-1, 256, 28, 28]               0\n",
      "           Conv2d-17           [-1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 28, 28]             128\n",
      "             ReLU-19           [-1, 64, 28, 28]               0\n",
      "           Conv2d-20           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 28, 28]             128\n",
      "             ReLU-22           [-1, 64, 28, 28]               0\n",
      "           Conv2d-23          [-1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 28, 28]             512\n",
      "             ReLU-25          [-1, 256, 28, 28]               0\n",
      "       Bottleneck-26          [-1, 256, 28, 28]               0\n",
      "           Conv2d-27           [-1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 28, 28]             128\n",
      "             ReLU-29           [-1, 64, 28, 28]               0\n",
      "           Conv2d-30           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 28, 28]             128\n",
      "             ReLU-32           [-1, 64, 28, 28]               0\n",
      "           Conv2d-33          [-1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 28, 28]             512\n",
      "             ReLU-35          [-1, 256, 28, 28]               0\n",
      "       Bottleneck-36          [-1, 256, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "             ReLU-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 14, 14]             256\n",
      "             ReLU-42          [-1, 128, 14, 14]               0\n",
      "           Conv2d-43          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 14, 14]           1,024\n",
      "           Conv2d-45          [-1, 512, 14, 14]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-47          [-1, 512, 14, 14]               0\n",
      "       Bottleneck-48          [-1, 512, 14, 14]               0\n",
      "           Conv2d-49          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 14, 14]             256\n",
      "             ReLU-51          [-1, 128, 14, 14]               0\n",
      "           Conv2d-52          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 14, 14]             256\n",
      "             ReLU-54          [-1, 128, 14, 14]               0\n",
      "           Conv2d-55          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-57          [-1, 512, 14, 14]               0\n",
      "       Bottleneck-58          [-1, 512, 14, 14]               0\n",
      "           Conv2d-59          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 14, 14]             256\n",
      "             ReLU-61          [-1, 128, 14, 14]               0\n",
      "           Conv2d-62          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 14, 14]             256\n",
      "             ReLU-64          [-1, 128, 14, 14]               0\n",
      "           Conv2d-65          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-67          [-1, 512, 14, 14]               0\n",
      "       Bottleneck-68          [-1, 512, 14, 14]               0\n",
      "           Conv2d-69          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 14, 14]             256\n",
      "             ReLU-71          [-1, 128, 14, 14]               0\n",
      "           Conv2d-72          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 14, 14]             256\n",
      "             ReLU-74          [-1, 128, 14, 14]               0\n",
      "           Conv2d-75          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-77          [-1, 512, 14, 14]               0\n",
      "       Bottleneck-78          [-1, 512, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 7, 7]             512\n",
      "             ReLU-84            [-1, 256, 7, 7]               0\n",
      "           Conv2d-85           [-1, 1024, 7, 7]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 7, 7]           2,048\n",
      "           Conv2d-87           [-1, 1024, 7, 7]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-89           [-1, 1024, 7, 7]               0\n",
      "       Bottleneck-90           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-91            [-1, 256, 7, 7]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 7, 7]             512\n",
      "             ReLU-93            [-1, 256, 7, 7]               0\n",
      "           Conv2d-94            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 7, 7]             512\n",
      "             ReLU-96            [-1, 256, 7, 7]               0\n",
      "           Conv2d-97           [-1, 1024, 7, 7]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-99           [-1, 1024, 7, 7]               0\n",
      "      Bottleneck-100           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-101            [-1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 7, 7]             512\n",
      "            ReLU-103            [-1, 256, 7, 7]               0\n",
      "          Conv2d-104            [-1, 256, 7, 7]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 7, 7]             512\n",
      "            ReLU-106            [-1, 256, 7, 7]               0\n",
      "          Conv2d-107           [-1, 1024, 7, 7]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-109           [-1, 1024, 7, 7]               0\n",
      "      Bottleneck-110           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-111            [-1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 7, 7]             512\n",
      "            ReLU-113            [-1, 256, 7, 7]               0\n",
      "          Conv2d-114            [-1, 256, 7, 7]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 7, 7]             512\n",
      "            ReLU-116            [-1, 256, 7, 7]               0\n",
      "          Conv2d-117           [-1, 1024, 7, 7]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-119           [-1, 1024, 7, 7]               0\n",
      "      Bottleneck-120           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-121            [-1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 7, 7]             512\n",
      "            ReLU-123            [-1, 256, 7, 7]               0\n",
      "          Conv2d-124            [-1, 256, 7, 7]         589,824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 256, 7, 7]             512\n",
      "            ReLU-126            [-1, 256, 7, 7]               0\n",
      "          Conv2d-127           [-1, 1024, 7, 7]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-129           [-1, 1024, 7, 7]               0\n",
      "      Bottleneck-130           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-131            [-1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 7, 7]             512\n",
      "            ReLU-133            [-1, 256, 7, 7]               0\n",
      "          Conv2d-134            [-1, 256, 7, 7]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 7, 7]             512\n",
      "            ReLU-136            [-1, 256, 7, 7]               0\n",
      "          Conv2d-137           [-1, 1024, 7, 7]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-139           [-1, 1024, 7, 7]               0\n",
      "      Bottleneck-140           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-141            [-1, 512, 7, 7]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-143            [-1, 512, 7, 7]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 72.70\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 170.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary(model, input_size=(3, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           1,792\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "            Conv2d-3         [-1, 64, 112, 112]          36,928\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6          [-1, 128, 56, 56]          73,856\n",
      "              ReLU-7          [-1, 128, 56, 56]               0\n",
      "            Conv2d-8          [-1, 128, 56, 56]         147,584\n",
      "              ReLU-9          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-10          [-1, 128, 28, 28]               0\n",
      "           Conv2d-11          [-1, 256, 28, 28]         295,168\n",
      "             ReLU-12          [-1, 256, 28, 28]               0\n",
      "           Conv2d-13          [-1, 256, 28, 28]         590,080\n",
      "             ReLU-14          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-15          [-1, 256, 14, 14]               0\n",
      "           Conv2d-16          [-1, 512, 14, 14]       1,180,160\n",
      "             ReLU-17          [-1, 512, 14, 14]               0\n",
      "           Conv2d-18          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-19          [-1, 512, 14, 14]               0\n",
      "         Upsample-20          [-1, 512, 28, 28]               0\n",
      "           Conv2d-21          [-1, 256, 28, 28]       1,769,728\n",
      "             ReLU-22          [-1, 256, 28, 28]               0\n",
      "           Conv2d-23          [-1, 256, 28, 28]         590,080\n",
      "             ReLU-24          [-1, 256, 28, 28]               0\n",
      "         Upsample-25          [-1, 256, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 56, 56]         442,496\n",
      "             ReLU-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28          [-1, 128, 56, 56]         147,584\n",
      "             ReLU-29          [-1, 128, 56, 56]               0\n",
      "         Upsample-30        [-1, 128, 112, 112]               0\n",
      "           Conv2d-31         [-1, 64, 112, 112]         110,656\n",
      "             ReLU-32         [-1, 64, 112, 112]               0\n",
      "           Conv2d-33         [-1, 64, 112, 112]          36,928\n",
      "             ReLU-34         [-1, 64, 112, 112]               0\n",
      "           Conv2d-35          [-1, 6, 112, 112]             390\n",
      "================================================================\n",
      "Total params: 7,783,238\n",
      "Trainable params: 7,783,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 113.50\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 143.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = pytorch_unet.UNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.210124, dice: 0.994346, loss: 0.602235\n",
      "val: bce: 0.030143, dice: 0.986439, loss: 0.508291\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 1/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.022030, dice: 0.806168, loss: 0.414099\n",
      "val: bce: 0.023499, dice: 0.671528, loss: 0.347514\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 2/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.023134, dice: 0.522101, loss: 0.272618\n",
      "val: bce: 0.017994, dice: 0.439513, loss: 0.228753\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 3/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.015791, dice: 0.392756, loss: 0.204273\n",
      "val: bce: 0.015154, dice: 0.353304, loss: 0.184229\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 4/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.012854, dice: 0.299000, loss: 0.155927\n",
      "val: bce: 0.011838, dice: 0.235490, loss: 0.123664\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 5/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.010764, dice: 0.217516, loss: 0.114140\n",
      "val: bce: 0.010928, dice: 0.202027, loss: 0.106478\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 6/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.010902, dice: 0.222725, loss: 0.116813\n",
      "val: bce: 0.010661, dice: 0.192998, loss: 0.101830\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 7/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.009604, dice: 0.184641, loss: 0.097122\n",
      "val: bce: 0.010067, dice: 0.181135, loss: 0.095601\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 8/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.009128, dice: 0.176201, loss: 0.092664\n",
      "val: bce: 0.008653, dice: 0.176254, loss: 0.092453\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 9/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.008457, dice: 0.170643, loss: 0.089550\n",
      "val: bce: 0.008299, dice: 0.171656, loss: 0.089977\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 10/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.007046, dice: 0.151076, loss: 0.079061\n",
      "val: bce: 0.005749, dice: 0.138535, loss: 0.072142\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 11/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004789, dice: 0.094846, loss: 0.049817\n",
      "val: bce: 0.004794, dice: 0.082758, loss: 0.043776\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 12/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003822, dice: 0.066693, loss: 0.035258\n",
      "val: bce: 0.004868, dice: 0.075574, loss: 0.040221\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 13/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003647, dice: 0.065981, loss: 0.034814\n",
      "val: bce: 0.005102, dice: 0.078447, loss: 0.041774\n",
      "0m 43s\n",
      "Epoch 14/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003680, dice: 0.068849, loss: 0.036265\n",
      "val: bce: 0.004177, dice: 0.066650, loss: 0.035413\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 15/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003029, dice: 0.053153, loss: 0.028091\n",
      "val: bce: 0.003654, dice: 0.061158, loss: 0.032406\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 16/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002797, dice: 0.050167, loss: 0.026482\n",
      "val: bce: 0.003610, dice: 0.059508, loss: 0.031559\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 17/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002720, dice: 0.049958, loss: 0.026339\n",
      "val: bce: 0.003184, dice: 0.057431, loss: 0.030307\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 18/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002537, dice: 0.046737, loss: 0.024637\n",
      "val: bce: 0.003113, dice: 0.054996, loss: 0.029055\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 19/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002300, dice: 0.044468, loss: 0.023384\n",
      "val: bce: 0.002945, dice: 0.051255, loss: 0.027100\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 20/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002042, dice: 0.040555, loss: 0.021299\n",
      "val: bce: 0.002866, dice: 0.050504, loss: 0.026685\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 21/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001988, dice: 0.038980, loss: 0.020484\n",
      "val: bce: 0.002593, dice: 0.047394, loss: 0.024993\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 22/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001841, dice: 0.036638, loss: 0.019239\n",
      "val: bce: 0.002522, dice: 0.045939, loss: 0.024230\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 23/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001795, dice: 0.035693, loss: 0.018744\n",
      "val: bce: 0.002727, dice: 0.044743, loss: 0.023735\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 24/39\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001691, dice: 0.034025, loss: 0.017858\n",
      "val: bce: 0.002360, dice: 0.043020, loss: 0.022690\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 25/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001572, dice: 0.031303, loss: 0.016437\n",
      "val: bce: 0.002217, dice: 0.040832, loss: 0.021524\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 26/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001514, dice: 0.030473, loss: 0.015993\n",
      "val: bce: 0.002166, dice: 0.040488, loss: 0.021327\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 27/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001501, dice: 0.030128, loss: 0.015815\n",
      "val: bce: 0.002229, dice: 0.040340, loss: 0.021285\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 28/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001496, dice: 0.029890, loss: 0.015693\n",
      "val: bce: 0.002166, dice: 0.040157, loss: 0.021162\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 29/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001488, dice: 0.029740, loss: 0.015614\n",
      "val: bce: 0.002215, dice: 0.040059, loss: 0.021137\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 30/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001479, dice: 0.029537, loss: 0.015508\n",
      "val: bce: 0.002149, dice: 0.039748, loss: 0.020948\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 31/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001469, dice: 0.029364, loss: 0.015416\n",
      "val: bce: 0.002212, dice: 0.039819, loss: 0.021016\n",
      "0m 43s\n",
      "Epoch 32/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001470, dice: 0.029170, loss: 0.015320\n",
      "val: bce: 0.002146, dice: 0.039689, loss: 0.020918\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 33/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001456, dice: 0.029055, loss: 0.015255\n",
      "val: bce: 0.002180, dice: 0.039492, loss: 0.020836\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 34/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001451, dice: 0.028900, loss: 0.015175\n",
      "val: bce: 0.002170, dice: 0.039412, loss: 0.020791\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 35/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001432, dice: 0.028700, loss: 0.015066\n",
      "val: bce: 0.002203, dice: 0.039768, loss: 0.020985\n",
      "0m 43s\n",
      "Epoch 36/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001433, dice: 0.028581, loss: 0.015007\n",
      "val: bce: 0.002091, dice: 0.039245, loss: 0.020668\n",
      "saving best model\n",
      "0m 43s\n",
      "Epoch 37/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001422, dice: 0.028358, loss: 0.014890\n",
      "val: bce: 0.002160, dice: 0.039272, loss: 0.020716\n",
      "0m 43s\n",
      "Epoch 38/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001414, dice: 0.028230, loss: 0.014822\n",
      "val: bce: 0.002143, dice: 0.039213, loss: 0.020678\n",
      "0m 43s\n",
      "Epoch 39/39\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.001406, dice: 0.027994, loss: 0.014700\n",
      "val: bce: 0.002083, dice: 0.039034, loss: 0.020559\n",
      "saving best model\n",
      "0m 43s\n",
      "Best val loss: 0.020559\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = pytorch_unet.UNet(num_class).to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 192, 192)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
